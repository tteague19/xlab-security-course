{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tteague19/xlab-security-course/blob/main/notebooks/05-defensive_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22d34354-07dc-49f0-8aca-1f30fe67acc8",
      "metadata": {
        "id": "22d34354-07dc-49f0-8aca-1f30fe67acc8"
      },
      "source": [
        "# Defensive Distillation\n",
        "\n",
        "The authors of [Distillation as a Defense to Adversarial\n",
        "Perturbations against Deep Neural Networks](https://arxiv.org/pdf/1511.04508) give a description of the four key ideas behind distilling image classifiers as a defense against adversarial examples.\n",
        "\n",
        "1. Start with hard labels (they describe this a series of one-hot vectors, but that is not necessarily how they would be stored in memory).\n",
        "2. Train the initial model using a traditional procedure, but let the final layer have a softmax with a temperature greater than one.\n",
        "3. Create a new training set using the outputs of this initial model. That is, instead of starting with hard labels like the previous model, we start with soft labels outputed by the initial model.\n",
        "4. Train a new model from scratch using the same architecture but with the soft labels (and with the same temperature as before).\n",
        "\n",
        "\n",
        "In this notebook, you will implement the final 2 steps and evaluate the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e27b4738-09b7-4a15-b642-cf69fe0ba227",
      "metadata": {
        "id": "e27b4738-09b7-4a15-b642-cf69fe0ba227",
        "outputId": "52d2f325-31b7-4c03-ecdb-10111f36812e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlab-security\n",
            "  Downloading xlab_security-0.1.13-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from xlab-security) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from xlab-security) (0.24.0+cpu)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from xlab-security) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from xlab-security) (3.10.0)\n",
            "Requirement already satisfied: pytest>=6.0 in /usr/local/lib/python3.12/dist-packages (from xlab-security) (8.4.2)\n",
            "Requirement already satisfied: openai>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from xlab-security) (2.12.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from xlab-security) (11.3.0)\n",
            "Requirement already satisfied: hf_xet in /usr/local/lib/python3.12/dist-packages (from xlab-security) (1.2.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from xlab-security) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.15.0->xlab-security) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.15.0->xlab-security) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.15.0->xlab-security) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.15.0->xlab-security) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.15.0->xlab-security) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.15.0->xlab-security) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.15.0->xlab-security) (4.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->xlab-security) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->xlab-security) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->xlab-security) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->xlab-security) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->xlab-security) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->xlab-security) (2.9.0.post0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->xlab-security) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->xlab-security) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->xlab-security) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->xlab-security) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->xlab-security) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.0.0->xlab-security) (1.3.1)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=6.0->xlab-security) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=6.0->xlab-security) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=6.0->xlab-security) (2.19.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->xlab-security) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->xlab-security) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->xlab-security) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->xlab-security) (3.1.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai>=1.0.0->xlab-security) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->xlab-security) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai>=1.0.0->xlab-security) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->xlab-security) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->xlab-security) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->xlab-security) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->xlab-security) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->xlab-security) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->xlab-security) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.0->xlab-security) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.15.0->xlab-security) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.15.0->xlab-security) (2.5.0)\n",
            "Downloading xlab_security-0.1.13-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlab-security\n",
            "Successfully installed xlab-security-0.1.13\n"
          ]
        }
      ],
      "source": [
        "# IF YOU ARE IN COLAB OR HAVE NOT INSTALLED `xlab-security`\n",
        "!pip install xlab-security # should not take more than a minute or two to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2c81c533-b7fc-4800-aa5b-e5d7c59eaf03",
      "metadata": {
        "id": "2c81c533-b7fc-4800-aa5b-e5d7c59eaf03"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Flatten, Linear, ReLU\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import xlab\n",
        "\n",
        "device = xlab.utils.get_best_device()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb6c350e-c645-44c2-a4a6-e70a771aedeb",
      "metadata": {
        "id": "cb6c350e-c645-44c2-a4a6-e70a771aedeb"
      },
      "source": [
        "### Preliminaries: Train an image classifer on hard labels\n",
        "\n",
        "We have already completed this step for you. We trained a simple MLP on the MNIST dataset on for two epochs and achieved a 94.90% accuracy on the test set. Importantly, we use a softmax with temperature ($T=20$) as described in our [explainer page](https://xlabaisecurity.com/adversarial/defensive-distillation/).\n",
        "\n",
        "\n",
        "If interested you can see the output of our training run [here](https://github.com/zroe1/xlab-ai-security/blob/main/models/defensive_distillation/training_output.txt) and the complete code [here](https://github.com/zroe1/xlab-ai-security/tree/main/models/defensive_distillation). You will train your own version of this model for step 5 of this notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9fe2b029-8ffa-47f7-b37a-04a369127aa6",
      "metadata": {
        "id": "9fe2b029-8ffa-47f7-b37a-04a369127aa6",
        "outputId": "652410e0-b795-4d40-e913-64a1e9768854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e63a759dc345401cb21a9441cc8e566e",
            "4a46c73f4c234d71b780c55ff701277b",
            "370a224aa315479fb39e10eff5999a69",
            "42809bd993d24590958a772bcce2b9c7",
            "94f92df854bf4cdea48042668bfe8e89",
            "a6a0b3dbd90645e7bd1b8a6f6e61e1ca",
            "c2f4a435157448fbaae5ece268fb71b5",
            "3d04014089274c48a991b018e0398e26",
            "0a974812821843d3be5fd14802897b76",
            "8f1b87ea4730467a833272d9e170c833",
            "92d1f17f18c4488bbf9dc0116d5c60ee"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mnist_mlp_temp_30.pth:   0%|          | 0.00/877k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e63a759dc345401cb21a9441cc8e566e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# skeleton of the model we trained\n",
        "class FeedforwardMNIST(nn.Module):\n",
        "    \"\"\"Simple 4-layer MLP for MNIST classification\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(FeedforwardMNIST, self).__init__()\n",
        "\n",
        "        input_size = 28 * 28\n",
        "        self.fc1 = Linear(input_size, 256)\n",
        "        self.fc2 = Linear(256, 64)\n",
        "        self.fc3 = Linear(64, num_classes)\n",
        "\n",
        "        self.flatten = Flatten()\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"uchicago-xlab-ai-security/base-mnist-model\",\n",
        "    filename=\"mnist_mlp_temp_30.pth\",\n",
        ")\n",
        "model = torch.load(model_path, map_location=device, weights_only=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a3cd05df-0e2c-4535-aa79-42407a8f1b79",
      "metadata": {
        "id": "a3cd05df-0e2c-4535-aa79-42407a8f1b79",
        "outputId": "e695a998-e684-429a-f941-828611b1b88e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeedforwardMNIST(\n",
            "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2d45200-0f5c-4cba-87a1-e4eeb18e9b9c",
      "metadata": {
        "id": "b2d45200-0f5c-4cba-87a1-e4eeb18e9b9c"
      },
      "source": [
        "### Benchmark on PGD\n",
        "\n",
        "We will benchmark on the pretained model you just loaded. Note that the model already has most of the resistence to adversarial attacks that you will see in this notebook. This is because we trained the model with a temperature greater than one which already accomplishes most of the smoothing. For comparison, the end of the notebook includes code for loading and benchmarking a model trained with a temperature of one, which you will see has almost 0% robustness against 100 iterations of PGD.\n",
        "\n",
        "When you train your distilled model you should only see a small reduction in attack success. This is actually expected! The authors of the original paper note that the distilled model should in theory converge to the original model but emperically it can offer some additional protection.\n",
        "\n",
        "If the original model is responsible for most of the protection you may wonder why we don't have you implement it. The reason we don't have you train the original model in this notebook is because it is extremely similar to what you will do in step 4. If you are interested, you should find it fairly easy to replace our pretrained model with your own implementation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "217f1e9c-cd59-49d8-aec4-e7d0605c2e55",
      "metadata": {
        "id": "217f1e9c-cd59-49d8-aec4-e7d0605c2e55",
        "outputId": "696a4dca-ed22-44fb-c819-9a2f34fae099",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:01<00:00, 5.99MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 158kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:01<00:00, 1.52MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 9.93MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29.0% of attacks succeded\n"
          ]
        }
      ],
      "source": [
        "num_test_imgs = 100\n",
        "imgs, ys = xlab.utils.load_mnist_test_samples(num_test_imgs)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "num_success = 0\n",
        "\n",
        "for img, y in zip(imgs, ys):\n",
        "    adv_x = xlab.utils.PGD(\n",
        "        model, loss_fn, img, y, epsilon=12 / 255, alpha=2 / 255, num_iters=20\n",
        "    )\n",
        "    adv_y = torch.argmax(model(adv_x))\n",
        "\n",
        "    if adv_y.item() != y:\n",
        "        num_success += 1\n",
        "\n",
        "print(f\"{(num_success / num_test_imgs) * 100:.4}% of attacks succeded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0cae8a8-abdf-43f1-bf95-e32e538e16d2",
      "metadata": {
        "id": "f0cae8a8-abdf-43f1-bf95-e32e538e16d2"
      },
      "source": [
        "## Task #1 and #2: Create new training set\n",
        "\n",
        "We will be training our distilled model on the labels of the pretrained model you have loaded above.\n",
        "\n",
        "\n",
        "The model you loaded however, gives logits, not a temperature-smoothed softmax, so to get the proper labels, you will first have to implement the function below which returns softmax with temperature.\n",
        "\n",
        "\n",
        "<details>\n",
        "<summary>üîê <b>Solution for Task #1</b></summary>\n",
        "\n",
        "```python\n",
        "def softmax_with_temp(inputs, T):\n",
        "    \"\"\"Applies temperature-scaled softmax to inputs\n",
        "    Args:\n",
        "        inputs [batch, features]: Input logits tensor.\n",
        "        T (float): Temperature scaling parameter.\n",
        "    Returns:\n",
        "        [batch, features]: Temperature-scaled softmax probabilities.\n",
        "    \"\"\"\n",
        "    out = inputs / T\n",
        "    return F.softmax(out, dim=1)\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "52423df3-dacf-4cc6-8d60-795b5f19b0b2",
      "metadata": {
        "id": "52423df3-dacf-4cc6-8d60-795b5f19b0b2"
      },
      "outputs": [],
      "source": [
        "def softmax_with_temp(inputs, T):\n",
        "    \"\"\"Applies temperature-scaled softmax to inputs\n",
        "    Args:\n",
        "        inputs [batch, features]: Input logits tensor.\n",
        "        T (float): Temperature scaling parameter.\n",
        "    Returns:\n",
        "        [batch, features]: Temperature-scaled softmax probabilities.\n",
        "    \"\"\"\n",
        "    return F.softmax(inputs / T, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9213a332-11b6-487d-a3be-ef5e9f97a5e6",
      "metadata": {
        "id": "9213a332-11b6-487d-a3be-ef5e9f97a5e6",
        "outputId": "647e1924-3909-45db-8b42-4c3f6f245b6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running tests for Defensive Distillation, Task 1...\n",
            "======================================================================\n",
            "üéâ All tests passed! (5/5)\n",
            "======================================================================\n",
            "\n",
            "Detailed output:\n",
            "============================= test session starts ==============================\n",
            "collecting ... collected 13 items / 8 deselected / 5 selected\n",
            "\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_softmax_with_temp_implementation[input_tensor0-1.0-basic functionality, T=1.0] PASSED [ 20%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_softmax_with_temp_implementation[input_tensor1-2.0-multi-batch, T=2.0] PASSED [ 40%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_softmax_with_temp_implementation[input_tensor2-0.5-temperature sharpening, T=0.5] PASSED [ 60%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_softmax_with_temp_implementation[input_tensor3-1.0-edge case: all zeros] PASSED [ 80%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_softmax_properties PASSED [100%]\n",
            "\n",
            "=============================== warnings summary ===============================\n",
            "../usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290\n",
            "../usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290\n",
            "  /usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; anyio\n",
            "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "================= 5 passed, 8 deselected, 2 warnings in 0.02s ==================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "_ = xlab.tests.distillation.task1(softmax_with_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2961b8d7-bed1-4014-b69c-cf4ce4d4121d",
      "metadata": {
        "id": "2961b8d7-bed1-4014-b69c-cf4ce4d4121d"
      },
      "source": [
        "Now you will find the labels for each batch by calling the model and running it's outputs through `softmax_with_temp`.\n",
        "\n",
        "<details>\n",
        "<summary>üîê <b>Solution for Task #2</b></summary>\n",
        "\n",
        "```python\n",
        "def get_batch_labels(batch, T):\n",
        "    \"\"\"Generates temperature-scaled probability distributions for a batch\n",
        "    Args:\n",
        "        batch [batch, *]: Input batch tensor.\n",
        "        T (float): Temperature scaling parameter.\n",
        "    Returns:\n",
        "        [batch, num_classes]: Temperature-scaled softmax probabilities.\n",
        "    \"\"\"\n",
        "    outs = model(batch)\n",
        "    outs = softmax_with_temp(outs, T)\n",
        "    return outs\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5f4e8ceb-d04f-4fdc-9267-76eefb158e22",
      "metadata": {
        "id": "5f4e8ceb-d04f-4fdc-9267-76eefb158e22"
      },
      "outputs": [],
      "source": [
        "def get_batch_labels(batch, T):\n",
        "    \"\"\"Generates temperature-scaled probability distributions for a batch\n",
        "    Args:\n",
        "        batch [batch, *]: Input batch tensor.\n",
        "        T (float): Temperature scaling parameter.\n",
        "    Returns:\n",
        "        [batch, num_classes]: Temperature-scaled softmax probabilities.\n",
        "    \"\"\"\n",
        "    outputs = model(batch)\n",
        "    return softmax_with_temp(inputs=outputs, T=T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f67bed46-e24c-408a-8cc9-ac725d8b4f41",
      "metadata": {
        "id": "f67bed46-e24c-408a-8cc9-ac725d8b4f41",
        "outputId": "bc60eb1b-cfa4-4903-c7e1-75a80d4c1a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running tests for Defensive Distillation, Task 2...\n",
            "======================================================================\n",
            "üéâ All tests passed! (4/4)\n",
            "======================================================================\n",
            "\n",
            "Detailed output:\n",
            "============================= test session starts ==============================\n",
            "collecting ... collected 13 items / 9 deselected / 4 selected\n",
            "\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_get_batch_labels_basic[1-1.0-single sample, T=1.0] PASSED [ 25%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_get_batch_labels_basic[3-2.0-small batch, T=2.0] PASSED [ 50%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_get_batch_labels_basic[2-0.5-batch of 2, T=0.5] PASSED [ 75%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_get_batch_labels_consistency PASSED [100%]\n",
            "\n",
            "=============================== warnings summary ===============================\n",
            "../usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290\n",
            "../usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290\n",
            "  /usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; anyio\n",
            "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "================= 4 passed, 9 deselected, 2 warnings in 0.02s ==================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "_ = xlab.tests.distillation.task2(get_batch_labels, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "91d7b6b3-731a-4328-ad50-03227af74427",
      "metadata": {
        "id": "91d7b6b3-731a-4328-ad50-03227af74427"
      },
      "outputs": [],
      "source": [
        "train_loader = xlab.utils.get_mnist_train_loader(batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "75b759a3-707a-4f66-836e-825875ad660d",
      "metadata": {
        "id": "75b759a3-707a-4f66-836e-825875ad660d"
      },
      "outputs": [],
      "source": [
        "imgs = []\n",
        "soft_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, _ in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        soft_labels_batch = get_batch_labels(x_batch, 30)\n",
        "\n",
        "        imgs.append(x_batch.cpu())\n",
        "        soft_labels.append(soft_labels_batch.cpu())\n",
        "\n",
        "all_images = torch.cat(imgs, dim=0)\n",
        "all_soft_labels = torch.cat(soft_labels, dim=0)\n",
        "soft_label_dataset = TensorDataset(all_images, all_soft_labels)\n",
        "\n",
        "batch_size = 128\n",
        "soft_label_loader = DataLoader(\n",
        "    soft_label_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4424649d-17d9-4cab-b187-b36c45271c7d",
      "metadata": {
        "id": "4424649d-17d9-4cab-b187-b36c45271c7d"
      },
      "source": [
        "The first step in contructing this new dataset is to implement `get_batch_labels` by calling the pretrained model with temperature T."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7420b6c4-6df6-497d-b027-d9a98f1d0e9d",
      "metadata": {
        "id": "7420b6c4-6df6-497d-b027-d9a98f1d0e9d"
      },
      "source": [
        "## Task #3 and #4: Train distilled model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "30eea637-de24-49fa-a296-f110eb84bdc3",
      "metadata": {
        "id": "30eea637-de24-49fa-a296-f110eb84bdc3"
      },
      "outputs": [],
      "source": [
        "# skeleton of the model we trained\n",
        "distilled = FeedforwardMNIST().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99d16656-6349-4f65-a85b-8fafbcbf1ddb",
      "metadata": {
        "id": "99d16656-6349-4f65-a85b-8fafbcbf1ddb"
      },
      "source": [
        "The optimization problem from the original paper was formalized by the authors using the following equation:\n",
        "\n",
        "$$\n",
        "\\arg\\min_{\\theta_F} -\\frac{1}{|\\mathcal{X}|} \\sum_{X \\in \\mathcal{X}} \\sum_{i \\in 0..N} F_i(X) \\log F_i^d(X)\n",
        "$$\n",
        "\n",
        "The loss for a single example is simply cross entropy loss with soft labels:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(X) = -\\sum_{i \\in 0..N} F_i(X) \\log F_i^d(X)\n",
        "$$\n",
        "\n",
        "<details>\n",
        "<summary>üîê <b>Solution for Task #3</b></summary>\n",
        "\n",
        "```python\n",
        "def cross_entropy_loss_soft(soft_labels, probs):\n",
        "    \"\"\"Computes cross-entropy loss between soft labels and predicted probabilities\n",
        "    Args:\n",
        "        soft_labels [batch, num_classes]: Target probability distributions.\n",
        "        probs [batch, num_classes]: Predicted probability distributions.\n",
        "    Returns:\n",
        "        scalar tensor: Normalized cross-entropy loss value.\n",
        "    \"\"\"\n",
        "    assert soft_labels.shape == probs.shape\n",
        "    batch_size = soft_labels.shape[0]\n",
        "\n",
        "    log_probs = torch.log(probs)\n",
        "    return torch.sum(-1 * log_probs *  soft_labels) / batch_size\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4569a3b2-cc57-41d7-803f-978d1898f5eb",
      "metadata": {
        "id": "4569a3b2-cc57-41d7-803f-978d1898f5eb"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_loss_soft(soft_labels, probs):\n",
        "    \"\"\"Computes cross-entropy loss between soft labels and predicted probabilities\n",
        "    Args:\n",
        "        soft_labels [batch, num_classes]: Target probability distributions.\n",
        "        probs [batch, num_classes]: Predicted probability distributions.\n",
        "    Returns:\n",
        "        scalar tensor: Normalized cross-entropy loss value.\n",
        "    \"\"\"\n",
        "\n",
        "    assert soft_labels.shape == probs.shape\n",
        "    batch_size = soft_labels.shape[0]\n",
        "\n",
        "    log_probs = torch.log(probs)\n",
        "    return (-1 / batch_size) * torch.sum(log_probs * soft_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "752d7530-4bcb-4037-96c0-448482ec7b5e",
      "metadata": {
        "id": "752d7530-4bcb-4037-96c0-448482ec7b5e",
        "outputId": "dd7852f6-cc6a-47e5-ad4a-1844f3d9e985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running tests for Defensive Distillation, Task 3...\n",
            "======================================================================\n",
            "üéâ All tests passed! (4/4)\n",
            "======================================================================\n",
            "\n",
            "Detailed output:\n",
            "============================= test session starts ==============================\n",
            "collecting ... collected 13 items / 9 deselected / 4 selected\n",
            "\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_cross_entropy_loss_soft_implementation[1-3-single sample, 3 classes] PASSED [ 25%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_cross_entropy_loss_soft_implementation[5-10-small batch, 10 classes] PASSED [ 50%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_cross_entropy_loss_soft_implementation[2-5-batch of 2, 5 classes] PASSED [ 75%]\n",
            "../usr/local/lib/python3.12/dist-packages/xlab/tests/distillation.py::test_cross_entropy_loss_one_hot_labels PASSED [100%]\n",
            "\n",
            "=============================== warnings summary ===============================\n",
            "../usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290\n",
            "../usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290\n",
            "  /usr/local/lib/python3.12/dist-packages/_pytest/config/__init__.py:1290: PytestAssertRewriteWarning: Module already imported so cannot be rewritten; anyio\n",
            "    self._mark_plugins_for_rewrite(hook, disable_autoload)\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "================= 4 passed, 9 deselected, 2 warnings in 0.02s ==================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "_ = xlab.tests.distillation.task3(cross_entropy_loss_soft)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dfd7bc9-e032-4abb-988b-a0c74ea4842e",
      "metadata": {
        "id": "4dfd7bc9-e032-4abb-988b-a0c74ea4842e"
      },
      "source": [
        "Now you will fill in the function to train your distilled model. Most of this work has already been done for you.\n",
        "\n",
        "Note that there are no tests for this task. You can evaluate the quality of your solution by benchmarking your model in the following section.\n",
        "\n",
        "<details>\n",
        "<summary>üîê <b>Solution for Task #4</b></summary>\n",
        "\n",
        "```python\n",
        "def train(model, epochs, train_loader, T):\n",
        "    \"\"\"Trains model using soft label cross-entropy loss with temperature scaling\n",
        "    Args:\n",
        "        model: Neural network model to train.\n",
        "        epochs (int): Number of training epochs.\n",
        "        train_loader: DataLoader providing batches of images and soft labels.\n",
        "        T (float): Temperature scaling parameter for softmax.\n",
        "    \"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (img, soft_label) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 1. get logits from model\n",
        "            img, soft_label = img.to(device), soft_label.to(device)\n",
        "            logits = model(img)\n",
        "\n",
        "            # 2. process the logits with softmax_with_temp\n",
        "            out = softmax_with_temp(logits, T)\n",
        "\n",
        "            # 3. compute batch loss\n",
        "            batch_loss = cross_entropy_loss_soft(soft_label, out)\n",
        "    \n",
        "            if i % 50==0:\n",
        "                print(f\"Epoch #{epoch + 1}: batch loss = {batch_loss.item():.4f}\")\n",
        "    \n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b59d88ff-77f4-4412-8f51-e84661bd3621",
      "metadata": {
        "id": "b59d88ff-77f4-4412-8f51-e84661bd3621"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, train_loader, T):\n",
        "    \"\"\"Trains model using soft label cross-entropy loss with temperature scaling\n",
        "    Args:\n",
        "        model: Neural network model to train.\n",
        "        epochs (int): Number of training epochs.\n",
        "        train_loader: DataLoader providing batches of images and soft labels.\n",
        "        T (float): Temperature scaling parameter for softmax.\n",
        "    \"\"\"\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (img, soft_label) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            ######### YOUR CODE STARTS HERE #########\n",
        "            # 1. get logits from model\n",
        "            logits = model(img.to(device))\n",
        "            # 2. process the logits with softmax_with_temp\n",
        "            output = softmax_with_temp(inputs=logits, T=T)\n",
        "            # 3. compute batch loss\n",
        "            batch_loss = cross_entropy_loss_soft(\n",
        "                soft_labels=soft_label.to(device), probs=output\n",
        "              )\n",
        "            ########## YOUR CODE ENDS HERE ##########\n",
        "\n",
        "            if i % 50 == 0:\n",
        "                print(f\"Epoch #{epoch + 1}: batch loss = {batch_loss.item():.4f}\")\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "09642d84-5b6c-4a3c-a62d-10ed48c41ef4",
      "metadata": {
        "scrolled": true,
        "id": "09642d84-5b6c-4a3c-a62d-10ed48c41ef4",
        "outputId": "a8a386c6-8e28-4b6e-f406-3d92c8089d28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch #1: batch loss = 2.3027\n",
            "Epoch #1: batch loss = 0.5587\n",
            "Epoch #1: batch loss = 0.4124\n",
            "Epoch #1: batch loss = 0.3124\n",
            "Epoch #1: batch loss = 0.3159\n",
            "Epoch #1: batch loss = 0.3410\n",
            "Epoch #1: batch loss = 0.2867\n",
            "Epoch #1: batch loss = 0.3068\n",
            "Epoch #1: batch loss = 0.2677\n",
            "Epoch #1: batch loss = 0.2929\n",
            "Epoch #2: batch loss = 0.2097\n",
            "Epoch #2: batch loss = 0.2531\n",
            "Epoch #2: batch loss = 0.2784\n",
            "Epoch #2: batch loss = 0.3137\n",
            "Epoch #2: batch loss = 0.2115\n",
            "Epoch #2: batch loss = 0.2471\n",
            "Epoch #2: batch loss = 0.2792\n",
            "Epoch #2: batch loss = 0.2309\n",
            "Epoch #2: batch loss = 0.2979\n",
            "Epoch #2: batch loss = 0.2718\n",
            "Epoch #3: batch loss = 0.2642\n",
            "Epoch #3: batch loss = 0.2192\n",
            "Epoch #3: batch loss = 0.2431\n",
            "Epoch #3: batch loss = 0.2130\n",
            "Epoch #3: batch loss = 0.2629\n",
            "Epoch #3: batch loss = 0.2325\n",
            "Epoch #3: batch loss = 0.2623\n",
            "Epoch #3: batch loss = 0.2723\n",
            "Epoch #3: batch loss = 0.2427\n",
            "Epoch #3: batch loss = 0.2512\n"
          ]
        }
      ],
      "source": [
        "train(distilled, 3, soft_label_loader, 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9bf0cd7-66ba-4df8-b1eb-abccf3c1428f",
      "metadata": {
        "id": "f9bf0cd7-66ba-4df8-b1eb-abccf3c1428f"
      },
      "source": [
        "## Benchmarking our Defense\n",
        "\n",
        "Below you should see that the clean accuracy is comparable to the original 94.90% accuracy. The attack success rate should be a bit below the success rate of the pretrained model. As we explained above, a lot of the protection comes from the original temperature smoothing, so you should not be surprised if the success rate is only slightly below the original pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "91a84edc-deed-4481-bc6a-a968a23c3247",
      "metadata": {
        "id": "91a84edc-deed-4481-bc6a-a968a23c3247",
        "outputId": "6c1406f5-c296-445a-bea0-74798e5e1ab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean accuracy of distilled model: 93.96%\n"
          ]
        }
      ],
      "source": [
        "clean_acc = xlab.utils.evaluate_mnist_accuracy(distilled)\n",
        "print(f\"Clean accuracy of distilled model: {clean_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f0ac639f-1c26-49ef-b822-295b63673538",
      "metadata": {
        "id": "f0ac639f-1c26-49ef-b822-295b63673538",
        "outputId": "b4bd262e-7837-4dc5-918b-3e661be9828f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32.0% of attacks succeded\n"
          ]
        }
      ],
      "source": [
        "num_test_imgs = 100\n",
        "imgs, ys = xlab.utils.load_mnist_test_samples(num_test_imgs)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "num_success = 0\n",
        "\n",
        "for img, y in zip(imgs, ys):\n",
        "    adv_x = xlab.utils.PGD(\n",
        "        distilled, loss_fn, img, y, epsilon=12 / 255, alpha=2 / 255, num_iters=20\n",
        "    )\n",
        "    adv_y = torch.argmax(distilled(adv_x))\n",
        "\n",
        "    if adv_y.item() != y:\n",
        "        num_success += 1\n",
        "\n",
        "print(f\"{(num_success / num_test_imgs) * 100:.4}% of attacks succeded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a8462726-a752-42e3-819c-57e9637169dd",
      "metadata": {
        "id": "a8462726-a752-42e3-819c-57e9637169dd",
        "outputId": "faf3126d-95a9-4c49-e84c-7cc7229e5a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9908b827a7bc4a43a73f46a5027d21aa",
            "76d4ddbc7e5744b9952ac7428695b5c0",
            "83f5e2bee4ed4d6f956aa25fa157774c",
            "8835db63cb654cc2901bd6d445ed5a4e",
            "c05dcd7592d34ad68e5fb765fcdd7ecd",
            "69a7932edf23466d8034789ad7be2d47",
            "84ebe7629c1646b787dbbcfa826b27ae",
            "6f9c32ea91e6415bb06b2ce4806a1c81",
            "dde9be05322340239003e1020c6fa811",
            "1f64fdbba4724a8d8d87276e8d62b3ad",
            "20b922b7fe7241ccb33cdb718b671c98"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mnist_mlp_temp_1.pth:   0%|          | 0.00/877k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9908b827a7bc4a43a73f46a5027d21aa"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_path = hf_hub_download(\n",
        "    repo_id=\"uchicago-xlab-ai-security/base-mnist-model\",\n",
        "    filename=\"mnist_mlp_temp_1.pth\",\n",
        ")\n",
        "standard = torch.load(model_path, map_location=device, weights_only=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "496ceec7-0150-4be7-8afc-15da019b86d6",
      "metadata": {
        "id": "496ceec7-0150-4be7-8afc-15da019b86d6"
      },
      "source": [
        "## Benchmarking a Traditional Model\n",
        "\n",
        "For reference, below you will the clean accuracy and attack success rate of a model with the same architecture trained with a softmax temperature of 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "45be25f0-38a9-4203-ae56-43447cc5edf8",
      "metadata": {
        "id": "45be25f0-38a9-4203-ae56-43447cc5edf8",
        "outputId": "10d8148c-74e7-4590-a4c4-2e84cd1deb5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean accuracy of standard model: 96.62%\n",
            "40.0% of attacks succeded\n"
          ]
        }
      ],
      "source": [
        "clean_acc = xlab.utils.evaluate_mnist_accuracy(standard)\n",
        "print(f\"Clean accuracy of standard model: {clean_acc * 100:.2f}%\")\n",
        "\n",
        "num_test_imgs = 30\n",
        "imgs, ys = xlab.utils.load_mnist_test_samples(num_test_imgs)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "num_success = 0\n",
        "\n",
        "for img, y in zip(imgs, ys):\n",
        "    adv_x = xlab.utils.PGD(\n",
        "        standard, loss_fn, img, y, epsilon=12 / 255, alpha=2 / 255, num_iters=10\n",
        "    )\n",
        "    adv_y = torch.argmax(standard(adv_x))\n",
        "\n",
        "    if adv_y.item() != y:\n",
        "        num_success += 1\n",
        "\n",
        "print(f\"{(num_success / num_test_imgs) * 100:.4}% of attacks succeded\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mD0jSMmkNjEg"
      },
      "id": "mD0jSMmkNjEg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e63a759dc345401cb21a9441cc8e566e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a46c73f4c234d71b780c55ff701277b",
              "IPY_MODEL_370a224aa315479fb39e10eff5999a69",
              "IPY_MODEL_42809bd993d24590958a772bcce2b9c7"
            ],
            "layout": "IPY_MODEL_94f92df854bf4cdea48042668bfe8e89"
          }
        },
        "4a46c73f4c234d71b780c55ff701277b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6a0b3dbd90645e7bd1b8a6f6e61e1ca",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c2f4a435157448fbaae5ece268fb71b5",
            "value": "mnist_mlp_temp_30.pth:‚Äá100%"
          }
        },
        "370a224aa315479fb39e10eff5999a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d04014089274c48a991b018e0398e26",
            "max": 876813,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a974812821843d3be5fd14802897b76",
            "value": 876813
          }
        },
        "42809bd993d24590958a772bcce2b9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f1b87ea4730467a833272d9e170c833",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_92d1f17f18c4488bbf9dc0116d5c60ee",
            "value": "‚Äá877k/877k‚Äá[00:03&lt;00:00,‚Äá222kB/s]"
          }
        },
        "94f92df854bf4cdea48042668bfe8e89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a0b3dbd90645e7bd1b8a6f6e61e1ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f4a435157448fbaae5ece268fb71b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d04014089274c48a991b018e0398e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a974812821843d3be5fd14802897b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f1b87ea4730467a833272d9e170c833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92d1f17f18c4488bbf9dc0116d5c60ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9908b827a7bc4a43a73f46a5027d21aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76d4ddbc7e5744b9952ac7428695b5c0",
              "IPY_MODEL_83f5e2bee4ed4d6f956aa25fa157774c",
              "IPY_MODEL_8835db63cb654cc2901bd6d445ed5a4e"
            ],
            "layout": "IPY_MODEL_c05dcd7592d34ad68e5fb765fcdd7ecd"
          }
        },
        "76d4ddbc7e5744b9952ac7428695b5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69a7932edf23466d8034789ad7be2d47",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_84ebe7629c1646b787dbbcfa826b27ae",
            "value": "mnist_mlp_temp_1.pth:‚Äá100%"
          }
        },
        "83f5e2bee4ed4d6f956aa25fa157774c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f9c32ea91e6415bb06b2ce4806a1c81",
            "max": 876801,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dde9be05322340239003e1020c6fa811",
            "value": 876801
          }
        },
        "8835db63cb654cc2901bd6d445ed5a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f64fdbba4724a8d8d87276e8d62b3ad",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_20b922b7fe7241ccb33cdb718b671c98",
            "value": "‚Äá877k/877k‚Äá[00:02&lt;00:00,‚Äá312kB/s]"
          }
        },
        "c05dcd7592d34ad68e5fb765fcdd7ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a7932edf23466d8034789ad7be2d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84ebe7629c1646b787dbbcfa826b27ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f9c32ea91e6415bb06b2ce4806a1c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde9be05322340239003e1020c6fa811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f64fdbba4724a8d8d87276e8d62b3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20b922b7fe7241ccb33cdb718b671c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}